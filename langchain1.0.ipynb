{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "79f4246c",
      "metadata": {},
      "source": [
        "# LangChain v1.0 Overview and Migration\n",
        "\n",
        "LangChain v1.0 doubles down on production agents. The release centers on the new `create_agent`, unified content blocks, and a streamlined namespace while leaning on LangGraph for persistence, streaming, human handoffs, and time travel out of the box.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2a85355",
      "metadata": {},
      "source": [
        "## What's New in LangChain v1.0\n",
        "\n",
        "- **`create_agent` as the default**: replaces `langgraph.prebuilt.create_react_agent` with a simpler API and first-class middleware hooks for context engineering and tool orchestration.\n",
        "- **Middleware pipeline**: built-in PII redaction, summarization, and human approval plus extensible hooks like `before_model`, `wrap_tool_call`, and `after_agent`.\n",
        "- **Structured outputs in the main loop**: `ToolStrategy` and `ProviderStrategy` eliminate extra model calls and cut cost.\n",
        "- **Standard content blocks**: provider-agnostic `message.content_blocks` expose reasoning, citations, and tool calls with type hints (Anthropic, AWS, OpenAI, Google, Ollama adapters today).\n",
        "- **LangGraph benefits included**: checkpoints, streaming, human-in-the-loop, and time travel with zero extra setup.\n",
        "- **Simplified namespace**: focused exports remain in `langchain.*` while legacy code moves to `langchain-classic`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbdc13cf",
      "metadata": {},
      "source": [
        "### Dummy tools used in the examples\n",
        "\n",
        "All examples share the same placeholder tools so they can be executed without external dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b23d67",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "DEFAULT_MODEL = \"openai:gpt-4o-mini\"\n",
        "PREMIUM_MODEL = \"openai:gpt-4o\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def read_email() -> str:\n",
        "    \"\"\"Dummy tool that returns inbox contents.\"\"\"\n",
        "    return \"No new emails found.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def send_email(recipient: str, subject: str, body: str) -> str:\n",
        "    \"\"\"Dummy tool that pretends to send an email.\"\"\"\n",
        "    return f\"Email to {recipient} queued.\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def search_web(query: str) -> str:\n",
        "    \"\"\"Dummy web search tool.\"\"\"\n",
        "    return f\"Search results for {query}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def analyze_data(dataset: str) -> str:\n",
        "    \"\"\"Dummy analytics tool.\"\"\"\n",
        "    return f\"Analysis for {dataset}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def weather_tool(city: str) -> str:\n",
        "    \"\"\"Return weather information for a city.\"\"\"\n",
        "    return f\"It is sunny and 70F in {city}\"\n",
        "\n",
        "\n",
        "assistant_tools = [read_email, send_email, search_web, analyze_data, weather_tool]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07ea815b",
      "metadata": {},
      "source": [
        "## Migration to LangChain v1.0\n",
        "\n",
        "> Note: install `langchain-classic` and adjust imports if you still rely on legacy chains, indexing, hub, or community exports.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ce4609",
      "metadata": {},
      "source": [
        "### Agent import\n",
        "\n",
        "Before:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc043542",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac7a4cbd",
      "metadata": {},
      "source": [
        "After:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c86dc64",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "\n",
        "agent = create_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        ")\n",
        "agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in Berlin?\"}]}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e83aeed",
      "metadata": {},
      "source": [
        "### System prompt parameter\n",
        "\n",
        "Before:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ffc81ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        "    prompt=\"Be frienly and helpful\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6faa93fc",
      "metadata": {},
      "source": [
        "After:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02304c03",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "\n",
        "agent = create_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        "    system_prompt=\"Be friendly and helpful.\",\n",
        ")\n",
        "agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in Berlin?\"}]}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a01c491",
      "metadata": {},
      "source": [
        "### Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfb827f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        ")\n",
        "\n",
        "inputs = {\"messages\": [\"Capital of France?\"]}\n",
        "agent.invoke(inputs, config={\"configurable\": {\"user_id\": \"42\"}})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd943f38",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from langchain.agents import create_agent\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Context:\n",
        "    user_id: str\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        "    context_schema=Context,\n",
        ")\n",
        "\n",
        "agent.invoke(inputs, context=Context(user_id=\"42\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1345931",
      "metadata": {},
      "source": [
        "### Dynamic prompts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3d8223d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
        "\n",
        "@dataclass\n",
        "class Context:  \n",
        "    user_role: str = \"user\"\n",
        "\n",
        "\n",
        "@dynamic_prompt\n",
        "def adjust_prompt(request: ModelRequest) -> str:\n",
        "    role = request.runtime.context.user_role\n",
        "    if role == \"expert\":\n",
        "        return \"You are a deep technical assistant.\"\n",
        "    return \"Explain concepts in plain language.\"\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        "    middleware=[adjust_prompt],\n",
        ")\n",
        "agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Explain async programming\"}]},\n",
        "    context=Context(user_role=\"expert\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef038967",
      "metadata": {},
      "source": [
        "### Pre-model hook to `before_model`\n",
        "\n",
        "Before:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ba3224",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "\n",
        "def summarize_history(state):\n",
        "    print(\"Dummy summarize\")\n",
        "    return state\n",
        "\n",
        "\n",
        "agent = create_react_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        "    pre_model_hook=summarize_history,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a97765f5",
      "metadata": {},
      "source": [
        "After:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b73f49dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import SummarizationMiddleware\n",
        "\n",
        "agent = create_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        "    middleware=[\n",
        "        SummarizationMiddleware(\n",
        "            model=DEFAULT_MODEL,\n",
        "            max_tokens_before_summary=500,\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "agent.invoke(\n",
        "    {\"messages\": [...]} # very long list of messages\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d17d3181",
      "metadata": {},
      "source": [
        "### Post-model hook to `after_model`\n",
        "\n",
        "Before:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd452a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "\n",
        "def human_review_hook(state, result):\n",
        "    print(\"Dummy review\")\n",
        "    return result\n",
        "\n",
        "\n",
        "agent = create_react_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        "    post_model_hook=human_review_hook,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dad5076c",
      "metadata": {},
      "source": [
        "After:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e2c0f07c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is the weather in Berlin?', additional_kwargs={}, response_metadata={}, id='880efa36-3892-4799-9f7d-2203473d1f96'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 135, 'total_tokens': 149, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CUGNcHATF4SmYkB7aEdjoQRbtjnPO', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--2fbbfa93-5956-4fb4-95bb-80e7d2c97733-0', tool_calls=[{'name': 'weather_tool', 'args': {'city': 'Berlin'}, 'id': 'call_4VQjNpoiTHevd3n2XHOGwfba', 'type': 'tool_call'}], usage_metadata={'input_tokens': 135, 'output_tokens': 14, 'total_tokens': 149, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              "  ToolMessage(content='It is sunny and 70F in Berlin', name='weather_tool', id='c23dbdf8-6748-490d-98d4-aa163b99b521', tool_call_id='call_4VQjNpoiTHevd3n2XHOGwfba'),\n",
              "  AIMessage(content='The weather in Berlin is sunny with a temperature of 70°F.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 166, 'total_tokens': 181, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CUGNdNIvQGiLC98tAKq3uwRfJ2XIr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--0673ff92-c52f-4a7b-9747-054a0ea8e027-0', usage_metadata={'input_tokens': 166, 'output_tokens': 15, 'total_tokens': 181, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
        "from langgraph.checkpoint.memory import InMemorySaver \n",
        "\n",
        "agent = create_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        "    middleware=[\n",
        "        HumanInTheLoopMiddleware(\n",
        "            interrupt_on={\n",
        "                \"send_email\": {\"allowed_decisions\": [\"approve\", \"reject\"]}\n",
        "            }\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in Berlin?\"}]}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "79467e99",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content=\"Send an email with 'hi' to my boss\", additional_kwargs={}, response_metadata={}, id='19a5c7f1-2a53-4bc9-9ca5-d48556254193'),\n",
              "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 138, 'total_tokens': 162, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CUGNpkdOXKcLo6fxJX2dud8VLM7Uc', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--216589c3-7750-43e6-96e1-1dbcacd41777-0', tool_calls=[{'name': 'send_email', 'args': {'recipient': 'boss@example.com', 'subject': 'Hello', 'body': 'hi'}, 'id': 'call_7oYmXPkMYM0XLD7ipQYv08hh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 138, 'output_tokens': 24, 'total_tokens': 162, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
              " '__interrupt__': [Interrupt(value={'action_requests': [{'name': 'send_email', 'args': {'recipient': 'boss@example.com', 'subject': 'Hello', 'body': 'hi'}, 'description': \"Tool execution requires approval\\n\\nTool: send_email\\nArgs: {'recipient': 'boss@example.com', 'subject': 'Hello', 'body': 'hi'}\"}], 'review_configs': [{'action_name': 'send_email', 'allowed_decisions': ['approve', 'reject']}]}, id='29c5bcda146fd424fbec491c91fecca6')]}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Send an email with 'hi' to my boss\"}]}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9bbf0bd",
      "metadata": {},
      "source": [
        "### Custom state with `AgentState`\n",
        "\n",
        "Before:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "81e6f497",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CustomState:\n",
        "    user_name: str\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11351340",
      "metadata": {},
      "source": [
        "After:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1e2a3468",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import AgentState\n",
        "\n",
        "\n",
        "class CustomState(AgentState):\n",
        "    user_name: str\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a062ff1",
      "metadata": {},
      "source": [
        "### Custom Middleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de585891",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents.middleware import AgentMiddleware\n",
        "from typing_extensions import NotRequired\n",
        "from typing import Any\n",
        "\n",
        "class CustomState(AgentState):\n",
        "    model_call_count: NotRequired[int]\n",
        "\n",
        "\n",
        "class CallCounterMiddleware(AgentMiddleware[CustomState]):\n",
        "    state_schema = CustomState  \n",
        "\n",
        "    def before_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n",
        "        count = state.get(\"model_call_count\", 0)\n",
        "        if count > 10:\n",
        "            return {\"jump_to\": \"end\"}\n",
        "        return None\n",
        "\n",
        "    def after_model(self, state: CustomState, runtime) -> dict[str, Any] | None:\n",
        "        return {\"model_call_count\": state.get(\"model_call_count\", 0) + 1}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19b260b",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent = create_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        "    middleware=[CallCounterMiddleware()],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1931aea",
      "metadata": {},
      "source": [
        "### Dynamic model selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdce2bdf",
      "metadata": {},
      "source": [
        "After:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4dfd206",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelRequestHandler\n",
        "\n",
        "\n",
        "class DynamicModel(AgentMiddleware):\n",
        "    \n",
        "    def wrap_model_call(self, request: ModelRequest, handler: ModelRequestHandler):\n",
        "        next_model = PREMIUM_MODEL if len(request.state.messages) > 10 else DEFAULT_MODEL\n",
        "        return handler(request.replace(model=next_model))\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=assistant_tools,\n",
        "    middleware=[DynamicModel()],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada12f05",
      "metadata": {},
      "source": [
        "### Structured output with the weather example"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbb7b704",
      "metadata": {},
      "source": [
        "After:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b473c2de",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "from langchain.agents.structured_output import ToolStrategy\n",
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class Weather(BaseModel):\n",
        "    temperature: float\n",
        "    condition: str\n",
        "\n",
        "\n",
        "agent = create_agent(\n",
        "    model=DEFAULT_MODEL,\n",
        "    tools=[weather_tool],\n",
        "    response_format=ToolStrategy(Weather),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48d2e9de",
      "metadata": {},
      "source": [
        "### Standard content blocks\n",
        "\n",
        "Before:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "52e4286c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The capital of France is Paris.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(DEFAULT_MODEL)\n",
        "response = model.invoke(\"Capital of France?\")\n",
        "print(response.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e50d9fa1",
      "metadata": {},
      "source": [
        "After:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3a055f56",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The capital of France is Paris.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(DEFAULT_MODEL)\n",
        "response = model.invoke(\"Capital of France?\")\n",
        "for block in response.content_blocks:\n",
        "    if block[\"type\"] == \"reasoning\":\n",
        "        print(block[\"reasoning\"])\n",
        "    elif block[\"type\"] == \"text\":\n",
        "        print(block[\"text\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc5169f",
      "metadata": {},
      "source": [
        "### Move legacy imports to `langchain-classic`\n",
        "\n",
        "Before:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0aae8abc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obvious import errors :)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from langchain.chains import LLMChain\n",
        "    from langchain import hub\n",
        "except:\n",
        "    print(\"Obvious import errors :)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64466fe7",
      "metadata": {},
      "source": [
        "After:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e2c73f37",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_classic.chains import LLMChain\n",
        "from langchain_classic import hub\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain10 (3.13.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
